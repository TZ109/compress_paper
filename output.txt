  공개특허 10-2018-0080986             (19) 대한민국특허청(KR)         (11) 공개번호   10-2018-0080986             (12) 공개특허공보(A)              (43) 공개일자   2018년07월13일(51) 국제특허분류(Int. Cl.)             (71) 출원인     G06Q 50/30 (2012.01)  G06N 3/02 (2006.01)             주식회사 플랫팜     G06N 99/00 (2010.01)  G06Q 50/00 (2018.01)            서울특별시 서초구 성촌길 33, 씨타워 8층(     G06Q 50/10 (2012.01)   우면동)(52) CPC특허분류         (72) 발명자     G06Q 50/30 (2015.01)   이효섭     G06N 3/02 (2013.01)     서울특별시 마포구 토정로 67, 502호(합정동, 두(21) 출원번호       10-2017-0171044(분할)   영 이지안아파트)(22) 출원일자       2017년12월13일     심사청구일자   없음 (62) 원출원         특허  10-2017-0001949     원출원일자     2017년01월05일     심사청구일자   2017년01월05일전체 청구항 수 : 총 10 항(54) 발명의 명칭 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 시스템(57) 요 약본 발명은 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 시스템에 관한 것이다. 본 발명의 일예와 관련된 머신 러닝 기반의 인공지능 이모티콘 제공 시스템에 있어서, 적어도 하나의 제 1 컨텐츠가 입력되는 제 1 단말; 상기 제 1 단말로부터 상기 제 1 컨텐츠를 수신하고, 상기 제 1 컨텐츠에 포함된 텍스트를 미리 설정된 단위로 분류하여 복수의 제 2 텍스트를 생성하며, 상기 복수의 제 2 텍스트 중 미리 설정된 조건을 만족하는 적어도 하나의 제 3 텍스트를 필터링하고, 미리 저장된 복수의 이모티콘 중 상기 제 3 텍스트에 매칭되는 적어도 하나의 제1 이모티콘을 결정하는 서버; 및 상기 서버로부터 상기 제 1 이모티콘을 수신하는 제 2 단말;을 포함할 수 있다.대 표 도 - 도1      공개특허 10-2018-0080986(52) CPC특허분류     G06N 99/005 (2013.01)     G06Q 50/01 (2013.01)     G06Q 50/10 (2015.01)      공개특허 10-2018-0080986명 세 서청구범위청구항 1 적어도 하나의 제 1 컨텐츠가 입력되는 제 1 단말;상기 제 1 단말로부터 상기 제 1 컨텐츠를 수신하고, 상기 제 1 컨텐츠에 포함된 텍스트를 미리 설정된 단위로분류하여 복수의 제 2 텍스트를 생성하며, 상기 복수의 제 2 텍스트 중 미리 설정된 조건을 만족하는 적어도 하나의 제 3 텍스트를 필터링하고, 미리 저장된 복수의 이모티콘 중 상기 제 3 텍스트에 매칭되는 적어도 하나의제 1 이모티콘을 결정하는 서버; 및상기 서버로부터 상기 제 1 이모티콘을 수신하는 제 2 단말;을 포함하는 머신 러닝 기반의 인공지능 이모티콘제공 시스템.청구항 2 제 1항에 있어서,상기 제 1 컨텐츠는, 텍스트 정보, 이미지 정보, 동영상 정보 및 음성 정보를 포함하는 것을 특징으로 하는 머신 러닝 기반의 인공지능 이모티콘 제공 시스템.청구항 3 제 2항에 있어서,상기 제 1 컨텐츠가 이미지 정보 또는 동영상 정보인 경우,상기 서버는, 상기 이미지 정보 또는 동영상 정보에 포함된 텍스트를 추출하고, 상기 추출한 텍스트를 상기 미리 설정된 단위로 분류하여 상기 복수의 제 2 텍스트를 생성하며,상기 제 1 컨텐츠가 음성 정보인 경우,상기 서버는, 상기 음성 정보를 텍스트 정보로 변환하고, 상기 변환된 텍스트 정보를 상기 미리 설정된 단위로분류하여 상기 복수의 제 2 텍스트를 생성하는 것을 특징으로 하는 머신 러닝 기반의 인공지능 이모티콘 제공시스템.청구항 4 제 1항에 있어서,상기 미리 설정된 단위는 형태소 단위이고,상기 서버는 상기 복수의 제 2 텍스트 중 적어도 일부를 기본형 동사로 변환하는 것을 특징으로 하는 머신 러닝기반의 인공지능 이모티콘 제공 시스템.청구항 5 제 1항에 있어서,상기 미리 설정된 조건은, 의미(meaning)를 갖는 텍스트인지 여부인 것을 특징으로 하는 머신 러닝 기반의 인공지능 이모티콘 제공 시스템.청구항 6 제 1항에 있어서,상기 제 3 텍스트는 복수이고,상기 복수의 제 3 텍스트에 매칭되는 제 1 이모티콘은 복수인 것을 특징으로 하는 머신 러닝 기반의 인공지능      공개특허 10-2018-0080986이모티콘 제공 시스템.청구항 7 제 6항에 있어서,상기 서버는,상기 복수의 제 3 텍스트를 미리 지정된 복수의 카테고리 중 적어도 하나의 카테고리로 분류하고,상기 분류된 상기 제 3 텍스트의 개수를 카테고리 별로 카운팅(counting)하며,상기 카테고리 별로 카운팅 된 결과값을 각 카테고리에 속한 제 3 텍스트에 부여하고,상기 미리 저장된 복수의 이모티콘 중 상기 복수의 제 3 텍스트에 매칭되는 복수의 제 1 이모티콘을 결정하며,상기 복수의 제 3 텍스트 각각의 결과값에 따라 상기 복수의 제 1 이모티콘의 배치 순서를 결정하는 것을 특징으로 하는 머신 러닝 기반의 인공지능 이모티콘 제공 시스템.청구항 8 제 7항에 있어서,상기 서버는, 상기 복수의 제 1 이모티콘과 상기 배치 순서를 상기 제 1 단말로 전송하고,상기 제 1 단말은,상기 복수의 제 1 이모티콘을 상기 배치 순서에 따라 표시하고,상기 제 1 단말의 사용자가 상기 복수의 제 1 이모티콘 중 제 2 이모티콘을 선택하는 경우, 상기 제 2 이모티콘에 대한 정보를 상기 서버로 전송하며,상기 서버는, 상기 제 2 이모티콘을 상기 제 2 단말로 전송하는 것을 특징으로 하는 머신 러닝 기반의 인공지능 이모티콘 제공 시스템.청구항 9 제 1항에 있어서,상기 제 1 단말을 통해 적어도 하나의 제 2 컨텐츠가 추가 입력되는 경우,상기 서버는 상기 제 1 단말로부터 상기 제 2 컨텐츠를 수신하고, 상기 제 2 컨텐츠에 포함된 텍스트를 미리 설정된 단위로 분류하여 복수의 제 2-2 텍스트를 생성하며, 상기 복수의 제 2-2 텍스트 중 미리 설정된 조건을 만족하는 적어도 하나의 제 3-2 텍스트를 필터링하고, 상기 미리 저장된 복수의 이모티콘 중 상기 제 3-2 텍스트에 매칭되는 적어도 하나의 제 1 이모티콘을 추가적으로 결정하는 것을 특징으로 하는 머신 러닝 기반의 인공지능 이모티콘 제공 시스템.청구항 10 제 1항에 있어서,상기 제 1 단말은 복수이고,상기 복수의 제 1 단말, 제 2 단말 및 서버 간의 동작에 관련된 데이터는 상기 서버에 저장되며,상기 서버는 상기 저장된 데이터를 누적하여 이용함으로써, 머신러닝(machine learning)을 수행하는 것을 특징으로 하는 머신 러닝 기반의 인공지능 이모티콘 제공 시스템.발명의 설명기 술 분 야      공개특허 10-2018-0080986           본 발명은 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 시스템에 관한 것이다.배 경 기 술           개인용 컴퓨터, 노트북, 휴대폰 등과 같은 단말기는 다양한 기능을 수행할 수 있도록 구성될 수 있다. 그러한다양한 기능들의 예로 데이터 및 음성 통신 기능, 카메라를 통해 사진이나 동영상을 촬영하는 기능, 음성 저장기능, 스피커 시스템을 통한 음악 파일의 재생 기능, 이미지나 비디오의 디스플레이 기능 등이 있다. 일부 단말기는 게임을 실행할 수 있는 추가적 기능을 포함하고, 다른 일부 단말기는 멀티미디어 기기로서 구현되기도 한다. 더욱이 최근의 단말기는 방송이나 멀티캐스트(multicast) 신호를 수신하여 비디오나 텔레비전 프로그램을시청할 수 있다.           일반적으로  단말기는  이동  가능  여부에  따라  이동  단말기(mobile/portable  terminal)  및  고정  단말기(stationary terminal)로 나뉠 수 있다. 다시 이동 단말기는 사용자의 직접 휴대 가능 여부에 따라 휴대(형) 단말기(handheld terminal) 및 거치형 단말기(vehicle mount terminal)로 나뉠 수 있다.           이와 같은 단말기(terminal)는 기능이 다양화됨에 따라 예를 들어, 사진이나 동영상의 촬영, 음악이나 동영상파일의 재생, 게임, 방송의 수신 등의 복합적인 기능들을 갖춘 멀티미디어 기기(Multimedia player) 형태로 구현되고 있다.           이러한 단말기의 기능 지지 및 증대를 위해, 단말기의 구조적인 부분 및/또는 소프트웨어적인 부분을 개량하는것이 고려될 수 있다.           한편, 단말을 이용한 모바일 환경에서 사용자의 소통하는 방식은 점차 비주얼 커뮤니케이션 중심으로 이동하고있으며, 사용자가 전달하고자 하는 메시지를 시각화하여 디자인해주는 에이전트가 필요하다.           현재 단말 사용자 자신만의 감성 표현을 위해 다양한 아이콘, 사진 등으로 소통하려는 시도가 있지만, 그 과정이 번거로워 섬세하고 풍부한 표현이 어렵다는 문제점이 있다.           따라서 인공지능과 디자인 테크놀로지를 더하고 다양한 캐릭터를 융합하여 즐거운 사용자 경험을 제공하는 방법이 요구되고 있는 실정이다.선행기술문헌특허문헌           (특허문헌 0001) 대한민국 특허청 출원번호 제10-2012-0131936호 발명의 내용해결하려는 과제           본 발명은 상기와 같은 종래의 문제점을 해결하기 위하여 안출된 것으로서, 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 시스템을 사용자에게 제공하는데 그 목적이 있다.            구체적으로 본 발명은 사용자의 메시지에 담긴 감정 요소와 맥락을 머신러닝 기반의 인공지능 기술로 분석하고캐릭터 이모티콘을 실시간으로 표현하는 시스템 및 어플리케이션을 사용자에게 제공하는데 그 목적이 있다.           본 발명은 메시지 분석을 통해 맥락 데이터(감정, 환경, 사물 등 요소)를 인식하고, 이를 시각적 의사소통 도구인 이모티콘으로 재가공하는 인공지능 기술 융합을 사용자에게 제공하는 것에 목적이 있다.           또한, 본 발명은 텍스트를 입력하는 사용 환경을 고려해서 특정 서비스나 어플리케이션에 국한하지 않고 범용으로 쓸 수 있는 어플리케이션 및 API를 사용자에게 제공하는 것에 목적이 있다.           또한, 본 발명은 사용자의 대화 습관 패턴을 학습하여 사용할수록 정확해지는 워드벡터 기반의 인공지능 머신러닝 시스템을 구축하고, 사용자에게 제공하는 것에 목적이 있다.           본 발명은 모바일 커뮤니케이션의 대부분을 차지하는 메시징 커뮤니케이션에 인공지능과 디자인 테크놀로지를접목하여 더 정확하고 편리한 커뮤니케이션 경험을 제안하고, 번거로운 사용과 제한된 표현으로 텍스트 보조역      공개특허 10-2018-0080986할에 그치는 현재의 이모티콘 사용 경험을 혁신하여 인공지능이 대화를 분석하고 실시간으로 그래픽 요소를 재조합하여 무한한 표현이 가능하도록 하는 것이 목적이다.           또한, 본 발명은 메시지 어플리케이션 뿐만 아니라 입력 인터페이스를 사용하는 SNS, 블로그, 미디어 등에서 끊임없이 창작되는 콘텐츠에 디자인을 입히는 테크놀로지로 발전시키는 것이 목적이다.           한편, 본 발명에서 이루고자 하는 기술적 과제들은 이상에서 언급한 기술적 과제들로 제한되지 않으며, 언급하지 않은 또 다른 기술적 과제들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을 것이다.과제의 해결 수단           상술한 과제를 실현하기 위한 본 발명의 일예와 관련된 머신 러닝 기반의 인공지능 이모티콘 제공 시스템에 있어서, 적어도 하나의 제 1 컨텐츠가 입력되는 제 1 단말; 상기 제 1 단말로부터 상기 제 1 컨텐츠를 수신하고,상기 제 1 컨텐츠에 포함된 텍스트를 미리 설정된 단위로 분류하여 복수의 제 2 텍스트를 생성하며, 상기 복수의 제 2 텍스트 중 미리 설정된 조건을 만족하는 적어도 하나의 제 3 텍스트를 필터링하고, 미리 저장된 복수의이모티콘 중 상기 제 3 텍스트에 매칭되는 적어도 하나의 제 1 이모티콘을 결정하는 서버; 및 상기 서버로부터상기 제 1 이모티콘을 수신하는 제 2 단말;을 포함할 수 있다.           또한, 상기 제 1 컨텐츠는, 텍스트 정보, 이미지 정보, 동영상 정보 및 음성 정보를 포함할 수 있다.           또한, 상기 제 1 컨텐츠가 이미지 정보 또는 동영상 정보인 경우, 상기 서버는, 상기 이미지 정보 또는 동영상정보에 포함된 텍스트를 추출하고, 상기 추출한 텍스트를 상기 미리 설정된 단위로 분류하여 상기 복수의 제 2텍스트를 생성하며, 상기 제 1 컨텐츠가 음성 정보인 경우, 상기 서버는, 상기 음성 정보를 텍스트 정보로 변환하고, 상기 변환된 텍스트 정보를 상기 미리 설정된 단위로 분류하여 상기 복수의 제 2 텍스트를 생성할 수 있다.           또한, 상기 미리 설정된 단위는 형태소 단위이고, 상기 서버는 상기 복수의 제 2 텍스트 중 적어도 일부를 기본형 동사로 변환할 수 있다.           또한, 상기 미리 설정된 조건은, 의미(meaning)를 갖는 텍스트인지 여부일 수 있다.           또한, 상기 제 3 텍스트는 복수이고, 상기 복수의 제 3 텍스트에 매칭되는 제 1 이모티콘은 복수일 수 있다.           또한, 상기 서버는, 상기 복수의 제 3 텍스트를 미리 지정된 복수의 카테고리 중 적어도 하나의 카테고리로 분류하고, 상기 분류된 상기 제 3 텍스트의 개수를 카테고리 별로 카운팅(counting)하며, 상기 카테고리 별로 카운팅 된 결과값을 각 카테고리에 속한 제 3 텍스트에 부여하고, 상기 미리 저장된 복수의 이모티콘 중 상기 복수의 제 3 텍스트에 매칭되는 복수의 제 1 이모티콘을 결정하며, 상기 복수의 제 3 텍스트 각각의 결과값에 따라 상기 복수의 제 1 이모티콘의 배치 순서를 결정할 수 있다.           또한, 상기 서버는, 상기 복수의 제 1 이모티콘과 상기 배치 순서를 상기 제 1 단말로 전송하고, 상기 제 1 단말은, 상기 복수의 제 1 이모티콘을 상기 배치 순서에 따라 표시하고, 상기 제 1 단말의 사용자가 상기 복수의제 1 이모티콘 중 제 2 이모티콘을 선택하는 경우, 상기 제 2 이모티콘에 대한 정보를 상기 서버로 전송하며,상기 서버는, 상기 제 2 이모티콘을 상기 제 2 단말로 전송할 수 있다.           또한, 상기 제 1 단말을 통해 적어도 하나의 제 2 컨텐츠가 추가 입력되는 경우, 상기 서버는 상기 제 1 단말로부터 상기 제 2 컨텐츠를 수신하고, 상기 제 2 컨텐츠에 포함된 텍스트를 미리 설정된 단위로 분류하여 복수의제 2-2 텍스트를 생성하며, 상기 복수의 제 2-2 텍스트 중 미리 설정된 조건을 만족하는 적어도 하나의 제 3-2텍스트를 필터링하고, 상기 미리 저장된 복수의 이모티콘 중 상기 제 3-2 텍스트에 매칭되는 적어도 하나의 제1 이모티콘을 추가적으로 결정할 수 있다.           또한, 상기 제 1 단말은 복수이고, 상기 복수의 제 1 단말, 제 2 단말 및 서버 간의 동작에 관련된 데이터는 상기 서버에 저장되며, 상기 서버는 상기 저장된 데이터를 누적하여 이용함으로써, 머신러닝(machine learning)을수행할 수 있다.발명의 효과           본 발명은 상기와 같은 종래의 문제점을 해결하기 위하여 안출된 것으로서, 머신 러닝 기반의 인공지능 이모티      공개특허 10-2018-0080986콘 서비스 제공 시스템을 사용자에게 제공할 수 있다.           구체적으로 본 발명은 사용자의 메시지에 담긴 감정 요소와 맥락을 머신러닝 기반의 인공지능 기술로 분석하고캐릭터 이모티콘을 실시간으로 표현하는 시스템 및 어플리케이션을 사용자에게 제공할 수 있다.           또한, 본 발명은 메시지 분석을 통해 맥락 데이터(감정, 환경, 사물 등 요소)를 인식하고, 이를 시각적 의사소통 도구인 이모티콘으로 재가공하는 인공지능 기술 융합을 사용자에게 제공할 수 있다.           또한, 본 발명은 텍스트를 입력하는 사용 환경을 고려해서 특정 서비스나 어플리케이션에 국한하지 않고 범용으로 쓸 수 있는 어플리케이션 및 API를 사용자에게 제공할 수 있다.           또한, 본 발명은 사용자의 대화 습관 패턴을 학습하여 사용할수록 정확해지는 워드벡터 기반의 인공지능 머신러닝 시스템을 구축하고, 사용자에게 제공할 수 있다.           또한, 본 발명은 모바일 커뮤니케이션의 대부분을 차지하는 메시징 커뮤니케이션에 인공지능과 디자인 테크놀로지를 접목하여 더 정확하고 편리한 커뮤니케이션 경험을 제안하고, 번거로운 사용과 제한된 표현으로 텍스트 보조역할에 그치는 현재의 이모티콘 사용 경험을 혁신하여 인공지능이 대화를 분석하고 실시간으로 그래픽 요소를재조합하여 무한한 표현이 가능하도록 할 수 있다.           또한, 본 발명은 메시지 어플리케이션뿐만 아니라 입력 인터페이스를 사용하는 SNS, 블로그, 미디어 등에서 끊임없이 창작되는 콘텐츠에 디자인을 입히는 테크놀로지로 발전시킬 수 있다.           또한,  본 발명은 구매한 캐릭터 이모티콘 콘텐츠를 반복적으로 사용하는 기존의 사용 방식과 달리 키워드,감정, 사용빈도, 기호, 기후, 날짜, 시간, 장소, 이슈 등 다양한 변수를 분석하고 조합하여 매번 새로운 디자인사용이 가능하다.           또한, 본 발명은 입력하는 단어나 기호(개수) 요소에 따라 캐릭터 이모티콘 표현이 실시간으로 변화하여 사용자는 자신의 감정을 확인하고 표현할 수 있다.           또한, 본 발명은 사용자 친화적인 UX 디자인을 통해 연산과정에서 발생하는 딜레이와 같은 기술적인 제약을 줄이고 커뮤니케이션 과정을 좀 더 사용자에게 친숙하게 전달할 수 있다.           또한, 본 발명은 머신 러닝을 통해 인공지능의 정확도를 지속적으로 높여갈 수 있다.           한편, 본 발명에서 얻을 수 있는 효과는 이상에서 언급한 효과들로 제한되지 않으며, 언급하지 않은 또 다른 효과들은 아래의 기재로부터 본 발명이 속하는 기술분야에서 통상의 지식을 가진 자에게 명확하게 이해될 수 있을것이다.도면의 간단한 설명           본 명세서에 첨부되는 다음의 도면들은 본 발명의 바람직한 일 실시례를 예시하는 것이며, 발명의 상세한 설명과 함께 본 발명의 기술적 사상을 더욱 이해시키는 역할을 하는 것이므로, 본 발명은 그러한 도면에 기재된 사항에만 한정되어 해석 되어서는 아니 된다.도 1은 본 발명이 제안하는 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 시스템의 블록구성도를 도시한 것이다.도 2는 본 발명에 적용되는 단말 또는 서버의 블록구성도를 도시한 것이다.도  3은  본  발명이  제안하는  머신  러닝  기반의  인공지능  이모티콘  서비스  제공  방법을  설명하기  위한순서도이다.도 4는 도 3에서 설명한 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 방법의 각 단계의 구체적인 일례를도시한 것이다.도 5는 본 발명과 관련하여, 사용자의 감정의 변화 또는 감정의 강도 변화에 따라 표현되는 이모티콘이 변화되는 구체적인 일례를 도시한 것이다.도 6은 본 발명의 다른 일 실시예와 관련하여, 연관성 순으로 이모티콘을 배열하여 사용자가 선택하는 방법을설명하는 순서도이다.도 7은 본 발명의 또 다른 일 실시예와 관련하여, 이모티콘의 전송 전에 사용자로부터 추가적인 메시지가 입력      공개특허 10-2018-0080986되는 경우, 실시간으로 이를 반영하여 연관성 있는 이모티콘을 사용자가 선택하는 방법을 설명하는 순서도이다.도 8은 도 6 또는 도 7에서 사용자가 입력한 컨텐츠를 통해 형태소를 분석하는 구체적인 일례를 도시한 것이다.도 9는 도 8에서 분석된 형태소를 기초로 키워드를 추출하는 본 발명의 구체적인 일례를 도시한 것이다.도 10은 도 9에서 추출한 키워드를 기초로 데이터 베이스 내 연관성 있는 이모티콘을 매칭하는 구체적인 작업의일례를 도시한 것이다.도 11은 도 10에서 매칭된 이모티콘을 연관성 순으로 사용자에게 배열하여 표시하는 구체적인 일례를 도시한 것이다.도 12는 도 11에서 표시된 복수의 이모티콘 중 하나를 사용자가 선택하여, 선택한 이모티콘을 전송하는 구체적인 일례를 도시한 것이다.도 13은 도 12에서 이모티콘의 전송 전에 사용자로부터 추가적인 메시지가 입력되는 경우, 실시간으로 이를 반영하는 구체적인 일례를 도시한 것이다.도 14 및 도 15는 본 발명과 관련하여, 영어의 경우에 머신 러닝 기반의 인공지능 이모티콘 서비스를 제공하는구체적인 일례를 도시한 것이다.발명을 실시하기 위한 구체적인 내용           이모티콘(Emoji) 시장은 밀레니엄 세대를 중심으로 확산되었으며 현재는 세대를 가리지 않고 대중적으로 사용되며 지난해 기준 하루에 전 세계 60억 건 이상의 이모티콘이 전송되었다고 한다(2015년, Oxford University).           이모티콘은 간편한 사용, 다양한 감정 표현으로 진화하고 있으며 텍스트 커뮤니케이션에 즐거움을 주는 보조 수단에서 텍스트의 한계를 보완하는 새로운 방식의 커뮤니케이션 수단으로 진화해나가고 있다.           이모티콘 (Emoji) 해외시장으로, 페이스북은 별도 메신저 어플리케이션으로 무료 이모티콘을 서비스하고 있고,중국 위챗은 유료 이모티콘을 판매한다.           또한, 스냅챗은 최근 1억 달러(약 1167억원)에 개인의 이모티콘을 제작해주는 Bitstrips을 인수하였다(2016년).           국내시장으로 이모티콘(이모지) 시장은 1000억 규모로 캐릭터 인형 등 파생상품 시장까지 더하면 2000억원대로추산되며 매년 사용량과 매출액에 있어 연 30-40% 사이의 급격한 성장세를 보이고 있다(2015년).           카카오톡에서 사용되는 이모티콘 수는 하루 평균 2억 개에 달하며 이모티콘 스토어 방문자는 월평균 2700만 명으로 카카오톡 이용자 10명 중 7명은 월 1회 이상 이모티콘 스토어를 이용하고 있다(2015년).           현재, 닌텐도에서 2016년 출시한 '미토모(Miitomo)는 자신은 닮은 아바타를 생성하고 활용하는 게임으로 출시 3일만에 100만 다운로드를 기록하는 등 좋은 반응을 얻고 있다.           또한, 캐릭터를 포함하는 것이 아니라 인터넷상에 유행하는 GIF파일을 태그로 분류하여 적절한 결과물을 찾아주는 키보드 어플 Fleksy, SharingGIF도 많은 사용자가 즐겨 사용하고 있다.           결국, 단말을 이용한 모바일 환경에서 사용자의 소통하는 방식은 점차 비주얼 커뮤니케이션 중심으로 이동하고있으며, 사용자가 전달하고자 하는 메시지를 시각화하여 디자인해주는 에이전트가 필요하다.           현재 단말 사용자 자신만의 감성 표현을 위해 다양한 아이콘, 사진 등으로 소통하려는 시도가 있지만, 그 과정이 번거로워 섬세하고 풍부한 표현이 어렵다는 문제점이 있다.           따라서 인공지능과 디자인 테크놀로지를 더하고 다양한 캐릭터를 융합하여 즐거운 사용자 경험을 제공하는 방법이 요구되고 있다.           본 발명은 상기와 같은 종래의 문제점을 해결하기 위하여 안출된 것으로서, 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 시스템을 사용자에게 제공하고자 한다.           구체적으로 본 발명은 사용자의 메시지에 담긴 감정 요소와 맥락을 머신러닝 기반의 인공지능 기술로 분석하고캐릭터 이모티콘을 실시간으로 표현하는 시스템 및 어플리케이션을 사용자에게 제공하는데 그 목적이 있다.           본 발명은 메시지 분석을 통해 맥락 데이터(감정, 환경, 사물 등 요소)를 인식하고, 이를 시각적 의사소통 도구인 이모티콘으로 재가공하는 인공지능 기술 융합을 사용자에게 제공하는 것에 목적이 있다.      공개특허 10-2018-0080986           또한, 본 발명은 텍스트를 입력하는 사용 환경을 고려해서 특정 서비스나 어플리케이션에 국한하지 않고 범용으로 쓸 수 있는 어플리케이션 및 API를 사용자에게 제공하는 것에 목적이 있다.           또한, 본 발명은 사용자의 대화 습관 패턴을 학습하여 사용할수록 정확해지는 워드벡터 기반의 인공지능 머신러닝 시스템을 구축하고, 사용자에게 제공하는 것에 목적이 있다.           또한, 본 발명은 모바일 커뮤니케이션의 대부분을 차지하는 메시징 커뮤니케이션에 인공지능과 디자인 테크놀로지를 접목하여 더 정확하고 편리한 커뮤니케이션 경험을 제안하고, 번거로운 사용과 제한된 표현으로 텍스트 보조역할에 그치는 현재의 이모티콘 사용 경험을 혁신하여 인공지능이 대화를 분석하고 실시간으로 그래픽 요소를재조합하여 무한한 표현이 가능하도록 하는 것에 목적이 있다.           또한, 본 발명은 메시지 어플리케이션뿐만 아니라 입력 인터페이스를 사용하는 SNS, 블로그, 미디어 등에서 끊임없이 창작되는 콘텐츠에 디자인을 입히는 테크놀로지로 발전시키는 것이 목적이다.           도 1은 본 발명이 제안하는 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 시스템의 블록구성도를 도시한 것이다.           도 1을 참조하면, 본 발명이 제안하는 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 시스템(1)은 컨텐츠 입력부(2), 이모티콘 생성부(3) 및 이모티콘 수신부(4)로 나뉠 수 있다.           컨텐츠 입력부(2)는 사용자로부터 텍스트, 보이스, 이미지, 동영상 등의 컨텐츠를 입력받는 기능을 제공한다.           다음으로, 이모티콘 생성부(3)는 컨텐츠 입력부(2)를 통해 입력받은 컨텐츠를 기초로 맥락을 파악하여 가장 적절한 이모티콘으로 자동 변환하고 전송하는 기능을 제공한다.           또한, 이모티콘 수신부(4) 는 이모티콘 생성부(3)로부터 이모티콘 데이터를 수신하여 사용자에게 표시하는 기능을 제공한다.           컨텐츠 입력부(2), 이모티콘 생성부(3) 및 이모티콘 수신부(4) 각각은 단말 또는 서버가 될 수 있다.           또한, 컨텐츠 입력부(2), 이모티콘 생성부(3) 및 이모티콘 수신부(4)는 근거리 통신 또는 원거리 통신을 이용하여 서로 간의 데이터를 교환할 수 있다.           여기서 적용되는 근거리 통신은 블루투스(Bluetooth), RFID(Radio Frequency Identification), 적외선 통신(IrDA, infrared Data Association), UWB(Ultra Wideband), ZigBee, Wi-Fi (Wireless Fidelity) 기술을 포함할 수 있다.           또한,  적용되는  원거리  통신은  CDMA(code  division  multiple  access),  FDMA(frequency  division  multipleaccess), TDMA(time division multiple access), OFDMA(orthogonal frequency division multiple access),SC-FDMA(single carrier frequency division multiple access) 기술을 포함할 수 있다.           본 발명이 제안하는 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 시스템(1)의 기능을 설명하기에 앞서, 컨텐츠 입력부(2), 이모티콘 생성부(3) 또는 이모티콘 수신부(4)이 될 수 있는 단말 또는 서버에 대해 구체적으로설명한다.           도 2는 본 발명에 적용되는 단말 또는 서버의 블록구성도를 도시한 것이다.           도  2를  참조하면  단말 또는 서버(100)는 무선 통신부(110),  A/V(Audio/Video)  입력부(120),  사용자 입력부(130), 센싱부(140), 출력부(150), 메모리(160), 인터페이스부(170), 제어부(180) 및 전원 공급부(190) 등을포함할 수 있다.            단, 도 2에 도시된 구성요소들이 필수적인 것은 아니어서, 그보다 많은 구성요소들을 갖거나 그보다 적은 구성요소들을 갖는 단말 또는 서버(100) 장치가 구현될 수도 있다.           이하, 상기 구성요소들에 대해 차례로 살펴본다.           무선 통신부(110)는 단말 장치와 무선 통신 시스템 사이 또는 단말 장치와 단말 장치가 위치한 네트워크 사이의무선 통신을 가능하게 하는 하나 이상의 모듈을 포함할 수 있다. 예를 들어, 무선 통신부(110)는 방송 수신 모듈(111), 이동통신 모듈(112), 무선 인터넷 모듈(113), 근거리 통신 모듈(114) 및 위치정보 모듈(115) 등을 포함할 수 있다.           방송 수신 모듈(111)은 방송 채널을 통하여 외부의 방송 관리 서버로부터 방송 신호 및/또는 방송 관련된 정보      공개특허 10-2018-0080986를 수신한다.            상기 방송 채널은 위성 채널, 지상파 채널을 포함할 수 있다. 상기 방송 관리 서버는, 방송 신호 및/또는 방송관련 정보를 생성하여 송신하는 서버 또는 기 생성된 방송 신호 및/또는 방송 관련 정보를 제공받아 단말기에송신하는 서버를 의미할 수 있다. 상기 방송 신호는, TV 방송 신호, 라디오 방송 신호, 데이터 방송 신호를 포함할 뿐만 아니라, TV 방송 신호 또는 라디오 방송 신호에 데이터 방송 신호가 결합한 형태의 방송 신호도 포함할 수 있다.            상기 방송 관련 정보는, 방송 채널, 방송 프로그램 또는 방송 서비스 제공자에 관련한 정보를 의미할 수 있다.상기 방송 관련 정보는, 이동통신망을 통하여도 제공될 수 있다. 이러한 경우에는 상기 이동통신 모듈(112)에의해 수신될 수 있다.           상기 방송 관련 정보는 다양한 형태로 존재할 수 있다. 예를 들어, DMB(Digital Multimedia Broadcasting)의EPG(Electronic  Program  Guide)  또는  DVB-H(Digital  Video  Broadcast-Handheld)의 ESG(Electronic  ServiceGuide) 등의 형태로 존재할 수 있다.           상기  방송  수신  모듈(111)은,  예를  들어,  DMB-T(Digital  Multimedia  Broadcasting-Terrestrial),  DMB-S(Digital Multimedia Broadcasting-Satellite), MediaFLO(Media Forward Link Only), DVB-H(Digital VideoBroadcast-Handheld), ISDB-T(Integrated Services Digital Broadcast-Terrestrial) 등의 디지털 방송 시스템을 이용하여 디지털 방송 신호를 수신할 수 있다. 물론, 상기 방송 수신 모듈(111)은, 상술한 디지털 방송 시스템뿐만 아니라 다른 방송 시스템에 적합하도록 구성될 수도 있다.           방송 수신 모듈(111)을 통해 수신된 방송 신호 및/또는 방송 관련 정보는 메모리(160)에 저장될 수 있다.           이동통신 모듈(112)은, 이동 통신망 상에서 기지국, 외부의 단말, 서버 중 적어도 하나와 무선 신호를 송수신한다. 상기 무선 신호는, 음성 호 신호, 화상 통화 호 신호 또는 문자/멀티미디어 메시지 송수신에 따른 다양한형태의 데이터를 포함할 수 있다.            무선 인터넷 모듈(113)은 무선 인터넷 접속을 위한 모듈을 말하는 것으로, 단말 장치에 내장되거나 외장될 수있다.   무선   인터넷   기술로는   WLAN(Wireless   LAN)(Wi-Fi),   Wibro(Wireless   broadband),   Wimax(WorldInteroperability for Microwave Access), HSDPA(High Speed Downlink Packet Access) 등이 이용될 수 있다.            근거리 통신 모듈(114)은 근거리 통신을 위한 모듈을 말한다. 근거리 통신(short range communication) 기술로블루투스(Bluetooth),   RFID(Radio   Frequency   Identification),   적외선   통신(IrDA,   infrared   DataAssociation), UWB(Ultra Wideband), ZigBee 등이 이용될 수 있다.           위치정보 모듈(115)은 단말 장치의 위치를 획득하기 위한 모듈로서, 그의 대표적인 예로는 GPS(Global PositionSystem) 모듈이 있다.           도 2를 참조하면, A/V(Audio/Video) 입력부(120)는 오디오 신호 또는 비디오 신호 입력을 위한 것으로, 이에는카메라(121)와 마이크(122) 등이 포함될 수 있다. 카메라(121)는 화상 통화모드 또는 촬영 모드에서 이미지 센서에 의해 얻어지는 정지영상 또는 동영상 등의 화상 프레임을 처리한다. 처리된 화상 프레임은 디스플레이부(151)에 표시될 수 있다.           카메라(121)에서 처리된 화상 프레임은 메모리(160)에 저장되거나 무선 통신부(110)를 통하여 외부로 전송될 수있다. 카메라(121)는 사용 환경에 따라 2개 이상이 구비될 수도 있다.           마이크(122)는 통화모드 또는 녹음모드, 음성인식 모드 등에서 마이크로폰(Microphone)에 의해 외부의 음향 신호를 입력받아 전기적인 음성 데이터로 처리한다. 처리된 음성 데이터는 통화 모드인 경우 이동통신 모듈(112)을 통하여 이동통신 기지국으로 송신 가능한 형태로 변환되어 출력될 수 있다. 마이크(122)에는 외부의 음향 신호를 입력받는 과정에서 발생되는 잡음(noise)을 제거하기 위한 다양한 잡음 제거 알고리즘이 구현될 수 있다.           사용자 입력부(130)는 사용자가 단말기의 동작 제어를 위한 입력 데이터를 발생시킨다. 사용자 입력부(130)는키 패드(key pad) 돔 스위치 (dome switch), 터치 패드(정압/정전), 조그 휠, 조그 스위치 등으로 구성될 수 있다.            센싱부(140)는 단말 장치의 개폐 상태, 단말 장치의 위치, 사용자 접촉 유무, 단말 장치의 방위, 단말 장치의가속/감속 등과 같이 단말 장치의 현 상태를 감지하여 단말 장치의 동작을 제어하기 위한 센싱 신호를 발생시킨다. 예를 들어 단말 장치가 슬라이드 폰 형태인 경우 슬라이드 폰의 개폐 여부를 센싱할 수 있다. 또한, 전원     공개특허 10-2018-0080986공급부(190)의 전원 공급 여부, 인터페이스부(170)의 외부 기기 결합 여부 등을 센싱할 수도 있다. 한편, 상기센싱부(140)는 근접 센서(141)를 포함할 수 있다.            출력부(150)는 시각, 청각 또는 촉각 등과 관련된 출력을 발생시키기 위한 것으로, 이에는 디스플레이부(151),음향 출력 모듈(152), 알람부(153), 햅틱 모듈(154) 및 프로젝터 모듈(155) 등이 포함될 수 있다.           디스플레이부(151)는 단말 장치에서 처리되는 정보를 표시(출력)한다. 예를 들어, 단말 장치가 통화 모드인 경우 통화와 관련된 UI(User Interface) 또는 GUI(Graphic User Interface)를 표시한다. 단말 장치가 화상 통화모드 또는 촬영 모드인 경우에는 촬영 또는/및 수신된 영상 또는 UI, GUI를 표시한다.            디스플레이부(151)는 액정 디스플레이(liquid crystal display, LCD), 박막 트랜지스터 액정 디스플레이(thinfilm  transistor-liquid  crystal  display,  TFT  LCD),  유기  발광  다이오드(organic  light-emitting  diode,OLED), 플렉시블 디스플레이(flexible display), 3차원 디스플레이(3D display) 중에서 적어도 하나를 포함할수 있다.            이들 중 일부 디스플레이는 그를 통해 외부를 볼 수 있도록 투명형 또는 광투과형으로 구성될 수 있다. 이는 투명 디스플레이라 호칭될 수 있는데, 상기 투명 디스플레이의 대표적인 예로는 TOLED(Transparant OLED) 등이 있다. 디스플레이부(151)의 후방 구조 또한 광 투과형 구조로 구성될 수 있다. 이러한 구조에 의하여, 사용자는단말기 바디의 디스플레이부(151)가 차지하는 영역을 통해 단말기 바디의 후방에 위치한 사물을 볼 수 있다.           단말 장치의 구현 형태에 따라 디스플레이부(151)이 2개 이상 존재할 수 있다. 예를 들어, 단말 장치에는 복수의 디스플레이부들이 하나의 면에 이격되거나 일체로 배치될 수 있고, 또한 서로 다른 면에 각각 배치될 수도있다.            디스플레이부(151)와 터치 동작을 감지하는 센서(이하, '터치 센서'라 함)가 상호 레이어 구조를 이루는 경우(이하, '터치 스크린'이라 함)에, 디스플레이부(151)는 출력 장치 이외에 입력 장치로도 사용될 수 있다. 터치센서는, 예를 들어, 터치 필름, 터치 시트, 터치 패드 등의 형태를 가질 수 있다.           터치 센서는 디스플레이부(151)의 특정 부위에 가해진 압력 또는 디스플레이부(151)의 특정 부위에 발생하는 정전 용량 등의 변화를 전기적인 입력신호로 변환하도록 구성될 수 있다. 터치 센서는 터치 되는 위치 및 면적뿐만 아니라, 터치 시의 압력까지도 검출할 수 있도록 구성될 수 있다.            터치 센서에 대한 터치 입력이 있는 경우, 그에 대응하는 신호(들)는 터치 제어기로 보내진다. 터치 제어기는그 신호(들)를 처리한 다음 대응하는 데이터를 제어부(180)로 전송한다. 이로써, 제어부(180)는 디스플레이부(151)의 어느 영역이 터치 되었는지 여부 등을 알 수 있게 된다.           상기 근접 센서(141)는 상기 터치스크린에 의해 감싸지는 단말 장치의 내부 영역 또는 상기 터치 스크린의 근처에 배치될 수 있다. 상기 근접 센서는 소정의 검출면에 접근하는 물체, 혹은 근방에 존재하는 물체의 유무를 전자계의 힘 또는 적외선을 이용하여 기계적 접촉이 없이 검출하는 센서를 말한다. 근접 센서는 접촉식 센서보다는 그 수명이 길며 그 활용도 또한 높다.            상기 근접 센서의 예로는 투과형 광전 센서, 직접 반사형 광전 센서, 미러 반사형 광전 센서, 고주파 발진형 근접 센서, 정전용량형 근접 센서, 자기형 근접 센서, 적외선 근접 센서 등이 있다. 상기 터치스크린이 정전식인경우에는 상기 포인터의 근접에 따른 전계의 변화로 상기 포인터의 근접을 검출하도록 구성된다. 이 경우 상기터치 스크린(터치 센서)은 근접 센서로 분류될 수도 있다.           이하에서는 설명의 편의를 위해, 상기 터치스크린 상에 포인터가 접촉되지 않으면서 근접되어 상기 포인터가 상기 터치스크린 상에 위치함이 인식되도록 하는 행위를 "근접 터치(proximity touch)"라고 칭하고, 상기 터치스크린 상에 포인터가 실제로 접촉되는 행위를 "접촉 터치(contact touch)"라고 칭한다. 상기 터치스크린 상에서포인터로 근접 터치가 되는 위치라 함은, 상기 포인터가 근접 터치될 때 상기 포인터가 상기 터치스크린에 대해수직으로 대응되는 위치를 의미한다.           상기 근접센서는, 근접 터치와, 근접 터치 패턴(예를 들어, 근접 터치 거리, 근접 터치 방향, 근접 터치 속도,근접 터치 시간, 근접 터치 위치, 근접 터치 이동 상태 등)을 감지한다. 상기 감지된 근접 터치 동작 및 근접터치 패턴에 상응하는 정보는 터치 스크린상에 출력될 수 있다.            또한, 색 감지 센서(142)는 외부의 대상에 포함된 색을 식별하는 기능을 제공하는 센서이다.           색 감지 센서(142)는 포토다이오드와 색 필터를 조합시켜 구성되는 색 식별센서로서, 특정한 색의 광량을 측정     공개특허 10-2018-0080986하는 단색의 색센서와, 중간색의 식별이 가능한 집적형 색센서가 있다.            단색의 색 센서는 비결정성, Si 포토다이오드의 앞면에 특정한 색투과 특성을 가진 필터를 접착한 것으로서, 입사광은 색필터에 의하여 어느 범위에 파장만이 투과하여 포토다이오드에 도달한다.            집적형 색센서는 1개의 기판 위에 집적된 3개의 포토다이오드의 앞면에 빛의 3원색에 상당하는 적(R), 녹(G),청(B)의 필터를 접착한 것이다.            그 때문에 입사광은 R, G, B의 성분만이 각 포토다이오드에 도달하기 때문에 빛의 3원색의 원리에 따라 본래의색을 식별할 수 있다.           또한, 본 발명에 따른 색 감지 센서(142)는 카메라(121)를 통해 촬영된 대상에 포함된 적어도 하나의 색을 감지하는 기능을 제공할 수도 있다.           또한, 디스플레이부(151)는 외부로 빛을 발산하는 빛 출력 기능을 제공할 수도 있다.           현재, 단말 또는 서버(100)에서 빛 출력 기능은 손전등 기능 등으로 제공되고 있다.           이러한 빛 출력 기능은 LED를 이용하는 구조를 통해 제공될 수도 있다.           단, 본 발명의 구성이 이에 한정되는 것은 아니고 빛을 외부로 발산하는 기술적 내용이 모두 접목될 수 있음은자명하다.           음향 출력 모듈(152)은 호신호 수신, 통화모드 또는 녹음 모드, 음성인식 모드, 방송수신 모드 등에서 무선 통신부(110)로부터 수신되거나 메모리(160)에 저장된 오디오 데이터를 출력할 수 있다. 음향 출력 모듈(152)은 단말 장치에서 수행되는 기능(예를 들어, 호신호 수신음, 메시지 수신음 등)과 관련된 음향 신호를 출력하기도 한다. 이러한 음향 출력 모듈(152)에는 리시버(Receiver), 스피커(speaker), 버저(Buzzer) 등이 포함될 수 있다.           알람부(153)는 단말 장치의 이벤트 발생을 알리기 위한 신호를 출력한다. 단말 장치에서 발생 되는 이벤트의 예로는 호 신호 수신, 메시지 수신, 키 신호 입력, 터치 입력 등이 있다. 알람부(153)는 비디오 신호나 오디오 신호 이외에 다른 형태, 예를 들어 진동으로 이벤트 발생을 알리기 위한 신호를 출력할 수도 있다. 상기 비디오신호나 오디오 신호는 디스플레이부(151)나 음성 출력 모듈(152)을 통해서도 출력될 수 있어서, 그들(151,152)은 알람부(153)의 일부로 분류될 수도 있다.           햅틱 모듈(haptic module)(154)은 사용자가 느낄 수 있는 다양한 촉각 효과를 발생시킨다. 햅틱 모듈(154)이 발생시키는 촉각 효과의 대표적인 예로는 진동이 있다. 햅택 모듈(154)이 발생하는 진동의 세기와 패턴 등은 제어가능하다. 예를 들어, 서로 다른 진동을 합성하여 출력하거나 순차적으로 출력할 수도 있다.            햅틱 모듈(154)은, 진동 외에도, 접촉 피부면에 대해 수직 운동하는 핀 배열, 분사구나 흡입구를 통한 공기의분사력이나 흡입력, 피부 표면에 대한 스침, 전극(eletrode)의 접촉, 정전기력 등의 자극에 의한 효과와, 흡열이나 발열 가능한 소자를 이용한 냉온감 재현에 의한 효과 등 다양한 촉각 효과를 발생시킬 수 있다.            햅틱 모듈(154)은 직접적인 접촉을 통해 촉각 효과의 전달할 수 있을 뿐만 아니라, 사용자가 손가락이나 팔 등의 근 감각을 통해 촉각 효과를 느낄 수 있도록 구현할 수도 있다. 햅틱 모듈(154)은 휴대 단말기의 구성 태양에 따라 2개 이상이 구비될 수 있다.           프로젝터 모듈(155)은, 단말 장치를 이용하여 이미지 프로젝트(project) 기능을 수행하기 위한 구성요소로서,제어부(180)의 제어 신호에 따라 디스플레이부(151)상에 디스플레이되는 영상과 동일하거나 적어도 일부가 다른영상을 외부 스크린 또는 벽에 디스플레이할 수 있다.           구체적으로, 프로젝터 모듈(155)은, 영상을 외부로 출력하기 위한 빛(일 예로서, 레이저 광)을 발생시키는 광원(미도시), 광원에 의해 발생한 빛을 이용하여 외부로 출력할 영상을 생성하기 위한 영상 생성 수단 (미도시),및 영상을 일정 초점 거리에서 외부로 확대 출력하기 위한 렌즈(미도시)를 포함할 수 있다. 또한, 프로젝터 모듈(155)은, 렌즈 또는 모듈 전체를 기계적으로 움직여 영상 투사 방향을 조절할 수 있는 장치(미도시)를 포함할수 있다.           프로젝터 모듈(155)은 디스플레이 수단의 소자 종류에 따라 CRT(Cathode Ray Tube) 모듈, LCD(Liquid CrystalDisplay) 모듈 및 DLP(Digital Light Processing) 모듈 등으로 나뉠 수 있다. 특히, DLP 모듈은, 광원에서 발생한 빛이 DMD(Digital Micromirror Device) 칩에 반사됨으로써 생성된 영상을 확대 투사하는 방식으로 프로젝터 모듈(151)의 소형화에 유리할 수 있다.     공개특허 10-2018-0080986           바람직하게, 프로젝터 모듈(155)은, 단말 장치의 측면, 정면 또는 배면에 길이 방향으로 구비될 수 있다. 물론,프로젝터 모듈(155)은, 필요에 따라 단말 장치의 어느 위치에라도 구비될 수 있음은 당연하다.           메모리부(160)는 제어부(180)의 처리 및 제어를 위한 프로그램이 저장될 수도 있고, 입/출력되는 데이터들(예를들어, 전화번호부, 메시지, 오디오, 정지영상, 동영상 등)의 임시 저장을 위한 기능을 수행할 수도 있다. 상기메모리부(160)에는 상기 데이터들 각각에 대한 사용 빈도(예를 들면, 각 전화번호, 각 메시지, 각 멀티미디어에대한 사용빈도)도 함께 저장될 수 있다. 또한, 상기 메모리부(160)에는 상기 터치스크린 상의 터치 입력시 출력되는 다양한 패턴의 진동 및 음향에 관한 데이터를 저장할 수 있다.           메모리(160)는 플래시 메모리 타입(flash memory type), 하드디스크 타입(hard disk type), 멀티미디어 카드마이크로  타입(multimedia  card  micro  type),  카드  타입의  메모리(예를  들어  SD  또는  XD  메모리  등),  램(Random  Access  Memory,  RAM),  SRAM(Static  Random  Access  Memory),  롬(Read-Only  Memory,  ROM),EEPROM(Electrically Erasable Programmable Read-Only Memory), PROM(Programmable Read-Only Memory), 자기메모리, 자기 디스크, 광디스크 중 적어도 하나의 타입의 저장매체를 포함할 수 있다. 단말 장치는 인터넷(internet)상에서 상기 메모리(160)의 저장 기능을 수행하는 웹 스토리지(web storage)와 관련되어 동작할 수도있다.           인터페이스부(170)는 단말 장치에 연결되는 모든 외부기기와의 통로 역할을 한다. 인터페이스부(170)는 외부 기기로부터 데이터를 전송받거나, 전원을 공급받아 단말 장치 내부의 각 구성 요소에 전달하거나, 단말 장치 내부의 데이터가 외부 기기로 전송되도록 한다. 예를 들어, 유/무선 헤드셋 포트, 외부 충전기 포트, 유/무선 데이터   포트,   메모리   카드(memory   card)   포트,   식별   모듈이   구비된   장치를   연결하는   포트,   오디오I/O(Input/Output) 포트, 비디오 I/O(Input/Output) 포트, 이어폰 포트 등이 인터페이스부(170)에 포함될 수있다.            식별 모듈은 단말 장치의 사용 권한을 인증하기 위한 각종 정보를 저장한 칩으로서, 사용자 인증 모듈(UserIdentify  Module,  UIM),  가입자  인증  모듈(Subscriber  Identify  Module,  SIM),  범용  사용자  인증  모듈(Universal Subscriber Identity Module, USIM) 등을 포함할 수 있다. 식별 모듈이 구비된 장치(이하 '식별 장치')는, 스마트 카드(smart card) 형식으로 제작될 수 있다. 따라서 식별 장치는 포트를 통하여 단말기와 연결될 수 있다.            상기 인터페이스부는 이동단말기가 외부 크래들(cradle)과 연결될 때 상기 크래들로부터의 전원이 상기 이동단말기에 공급되는 통로가 되거나, 사용자에 의해 상기 크래들에서 입력되는 각종 명령 신호가 상기 이동단말기로전달되는 통로가 될 수 있다. 상기 크래들로부터 입력되는 각종 명령 신호 또는 상기 전원은 상기 이동단말기가상기 크래들에 정확히 장착되었음을 인지하기 위한 신호로 동작될 수도 있다.           제어부(controller, 180)는 통상적으로 단말 장치의 전반적인 동작을 제어한다. 예를 들어 음성 통화, 데이터통신, 화상 통화 등을 위한 관련된 제어 및 처리를 수행한다. 제어부(180)는 멀티 미디어 재생을 위한 멀티미디어 모듈(181)을 구비할 수도 있다. 멀티미디어 모듈(181)은 제어부(180) 내에 구현될 수도 있고, 제어부(180)와별도로 구현될 수도 있다.           상기 제어부(180)는 상기 터치스크린 상에서 행해지는 필기 입력 또는 그림 그리기 입력을 각각 문자 및 이미지로 인식할 수 있는 패턴 인식 처리를 행할 수 있다.            전원 공급부(190)는 제어부(180)의 제어에 의해 외부의 전원, 내부의 전원을 인가받아 각 구성요소들의 동작에필요한 전원을 공급한다.           여기에 설명되는 다양한 실시예는 예를 들어, 소프트웨어, 하드웨어 또는 이들의 조합된 것을 이용하여 컴퓨터또는 이와 유사한 장치로 읽을 수 있는 기록매체 내에서 구현될 수 있다.           하드웨어적인 구현에 의하면, 여기에 설명되는 실시예는 ASICs (application specific integrated circuits),DSPs (digital signal processors), DSPDs (digital signal processing devices), PLDs (programmable logicdevices), FPGAs (field programmable gate arrays, 프로세서(processors), 제어기(controllers), 마이크로 컨트롤러(micro-controllers), 마이크로 프로세서(microprocessors), 기타 기능 수행을 위한 전기적인 유닛 중적어도 하나를 이용하여 구현될 수 있다. 일부의 경우에 본 명세서에서 설명되는 실시예들이 제어부(180) 자체로 구현될 수 있다.           소프트웨어적인 구현에 의하면, 본 명세서에서 설명되는 절차 및 기능과 같은 실시예들은 별도의 소프트웨어 모     공개특허 10-2018-0080986듈들로 구현될 수 있다. 상기 소프트웨어 모듈들 각각은 본 명세서에서 설명되는 하나 이상의 기능 및 작동을수행할 수 있다. 적절한 프로그램 언어로 쓰여진 소프트웨어 어플리케이션으로 소프트웨어 코드가 구현될 수 있다. 상기 소프트웨어 코드는 메모리(160)에 저장되고, 제어부(180)에 의해 실행될 수 있다.           전술한 이모티콘 서비스 제공 시스템(1)을 구성하는 컨텐츠 입력부(2), 이모티콘 생성부(3) 및 이모티콘 수신부(4)의 단말 또는 서버(100) 요소를 기초로 본 발명의 구체적인 기능을 설명한다.           또한, 컴파일 이후 iOS와 Android에 각각 대응하는 Native APIs로 변환하고, 다양한 디바이스에 효율적인 대응이 가능한 구조를 제안한다.           또한, 본 발명은 사용자의 채팅 데이터를 분석 가공된 키토큰의 형태로 DB로 저장하고, DB 누적된 사용자 데이터는 워드벡터 기반의 인공지능 정확도 제고에 다시 기여함으로써, 사용량이 늘어날 수록 인공지능의 정확도가높아지는 시스템을 제안한다(워드벡터 기반의 머신러닝).           또한,  본 발명은 구매한 캐릭터 이모티콘 콘텐츠를 반복적으로 사용하는 기존의 사용 방식과 달리 키워드,감정, 사용빈도, 기호, 기후, 날짜, 시간, 장소, 이슈 등 다양한 변수를 분석하고 조합하여 매번 새로운 디자인사용이 가능하다.           또한, 본 발명은 입력하는 단어나 기호(개수) 요소에 따라 캐릭터 이모티콘 표현이 실시간으로 변화하여 사용자는 자신의 감정을 확인하고 표현할 수 있다.           또한, 본 발명은 사용자 친화적인 UX 디자인을 통해 연산과정에서 발생하는 딜레이와 같은 기술적인 제약을 줄이고 커뮤니케이션 과정을 좀 더 사용자에게 친숙하게 전달할 수 있다.           또한, 본 발명은 머신러닝을 통해 인공지능의 정확도를 지속적으로 높여갈 수 있다.           도  3은  본  발명이  제안하는  머신  러닝  기반의  인공지능  이모티콘  서비스  제공  방법을  설명하기  위한순서도이다.           도 3을 참조하면, 본 발명에 따른 컨텐츠 입력부(2)의 단말 또는 서버(100)가 사용자로부터 텍스트, 보이스, 이미지, 동영상 등의 컨텐츠를 입력받는 단계(S110)가 가장 먼저 수행된다.           이후, 이모티콘 생성부(3)의 단말 또는 서버(100)는 입력된 컨텐츠를 기초로 형태소를 분석하게 된다(S120).           S120 단계에서는 단말 또는 서버(100)의 제어부(180)가 형태소를 분석하고, 표현된 단어를 기본형 동사로 변환하는 등의 작업을 통해 키토큰으로 변환하는 작업을 수행한다.           또한, S120 단계 이후에, 이모티콘 생성부(3)의 단말 또는 서버(100)는 동사, 명사, 형용사, 문장부호 등을 통해 S110 단계에서 입력된 컨텐츠의 맥락을 분석하는 작업을 수행한다(S130).           S130 단계를 거쳐, 이모티콘 생성부(3)의 단말 또는 서버(100)가 키토큰 정보를 기초로 이모티콘과 매칭하는 작업을 수행한다(S140).           S140 단계에서 단말 또는 서버(100)의 제어부(180)는 개별 이모티콘 태그를 적용하거나 이모티콘 카테고리를 통해 복수의 이모티콘을 이용할 수도 있다.           S140 단계에서 이모티콘 매칭 작업이 완료되면, 이모티콘 생성부(3)의 단말 또는 서버(100)는 이모티콘 수신부(4)의 단말 또는 서버(100)로 결정된 이모티콘을 전송하게 된다(S150).           결국, 본 발명은 텍스트 및 보이스 메시지의 감정, 맥락을 분석해서 이모티콘으로 자동 전송해주는 스마트 어플리케이션을 제공하게 된다.           이를 통해, 기존의 텍스트 방식으로는 표현하기 힘든 사용자의 감정을 1)인공지능 API로 분석하고 2)자체 에이전트를 활용하여 실시간으로 이모티콘을 디자인하여 서로의 감정을 교감할 수 있는 새로운 커뮤니케이션 경험을제공한다.           도 4는 도 3에서 설명한 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 방법의 각 단계의 구체적인 일례를도시한 것이다.           도 4를 참조하면, S110 단계의 일례로서, 사용자가 “치킨키칰치키이이이인치킨 먹으러 가자”라는 컨텐츠가 입력된다.     공개특허 10-2018-0080986           또한, 도 4를 참조하면, S120 단계의 일례로서, 이모티콘 생성부(3)의 단말 또는 서버(100)가 형태소 분석을 통해 “치킨”, “치키이이이”, “인”, “먹”, “으러”, “가자” 등을 추출하게 된다.           또한, S120 단계의 일례로서, 기본형 동사로 변형하는 작업이 수행되고, “먹”을 “먹다”로 변형하고, “가자”를 “가다”로 변형하게 된다.           이후, 도 4에서는 S130 단계의 일례로서, 형태소 분석된 “치킨”을 “배고플 때”, “먹다”를 “배고플 때”및 “배부를 때”로 카테고리 매칭하고, “가다”를 “신날 때”의 카테고리로 매칭할 수 있다.           또한, S140 단계의 일례로서, S120 단계에서 추출된 키토큰의 API 분석을 통해 “즐거움이 76%”, “슬픔이 42%”, “화남이 50%”, “두려움이 12%”, “놀람이 22%” 등의 상태를 추출할 수 있다.           이후, S130 및 S140 단계를 기초로, 확정된 이모티콘을 이모티콘 생성부(3)의 단말 또는 서버(100)는 이모티콘수신부(4)의 단말 또는 서버(100)로 결정된 이모티콘을 전송하게 된다(S150).           *결국, 자체 알고리즘과 외부 API를 활용하여 현재 입력하고 있는 텍스트의 복수의 상황(예를 들어, 49가지 상황)과 및 감정(Joy, Sadness, Anger, Fear, Surprise)에 대해 맥락과 뉘앙스를 분석하고, 이모티콘 디자인의감정톤(tone)을 정할 수 있다.           또한, 추출된 키워드와 매칭된 이미지를 생성하고 정해진 규칙에 맞춰 조합하여 이모티콘을 생성할 수도 있다.           한편, 본 발명에서는 S150 단계에서 다양한 변수를 조합하여 무한한 경우의 수의 이모티콘으로 표현할 수도 있다.           사용자는 자신의 감정과 상황이 정확한 분석을 통해 가장 적절한 이모티콘으로 변환되었을 때의 편리함과 감정이 교감되는 커뮤니케이션의 즐거움을 경험할 수 있다.           즉, 사용자의 감정, 대화의 전체적인 맥락, 사용된 키워드를 반영하여 이모티콘을 생성하고 클라우드의 콘텐츠를 불러오기 때문에 매번 상황에 맞게 제공할 수 있다.           또한, 본 발명에서는 결과물에 이미지 프로세싱을 적용하여 같은 이모티콘에서도 감정의 강도에 따라 다르게 표현 할 수 있으며 이를 통해 좀 더 섬세하게 의사소통 할 수 있다.           도 5는 본 발명과 관련하여, 사용자의 감정의 변화 또는 감정의 강도 변화에 따라 표현되는 이모티콘이 변화되는 구체적인 일례를 도시한 것이다.           도 5는 도 4에서 일예로 설명한 치킨과 관련된 이모티콘이 동일하게 표시되지만, (a), (b) 및 (c) 각각은 사용자의 감정의 변화 또는 감정의 강도 변화에 따라 색상, 크기 등이 변화되는 이모티콘이 표시되는 것의 일례를도시한 것이다.           한편, 본 발명의 다른 실시예에 따르면, 매칭되는 이모티콘을 사용자에게 제공하는 것 이외에 연관성 순으로 이모티콘을 배열하여 사용자가 선택하는 방법이 제공될 수도 있다.           도 6은 본 발명의 다른 일 실시예와 관련하여, 연관성 순으로 이모티콘을 배열하여 사용자가 선택하는 방법을설명하는 순서도이다.           도 6을 참조하면, 가장 먼저, 본 발명에 따른 컨텐츠 입력부(2)의 단말 또는 서버(100)가 사용자로부터 텍스트,보이스, 이미지, 동영상 등의 컨텐츠를 입력받는 단계(S110)가 가장 먼저 수행된다.           다음으로,  이모티콘  생성부(3)의  단말  또는  서버(100)는  입력된  컨텐츠를  기초로  형태소를  분석하게  된다(S120).           또한, S120 단계 이후에, 이모티콘 생성부(3)의 단말 또는 서버(100)는 동사, 명사, 형용사, 문장부호 등을 통해 S110 단계에서 입력된 컨텐츠의 맥락을 분석하는 작업을 수행한다(S130).           이후, 이모티콘 생성부(3)의 단말 또는 서버(100)가 키토큰 정보를 기초로 이모티콘과 매칭하는 작업을 수행하는데, 전술한 S140 단계와 달리 데이터베이스(DB) 내 이모티콘과의 연관성을 연산하여 이모티콘을 매칭하는 단계(S210)를 수행한다.           즉, 도 4에서 일례로 설명한 형태소 분석된 “치킨”을 “배고플 때”, “먹다”를 배고플 때” 및 “배부를 때     공개특허 10-2018-0080986”로 카테고리 매칭하고, “가다”를 “신날 때”의 카테고리로 매칭한 경우, 매칭된 카테고리와의 연관성을 연산하여 이모티콘을 매칭할 수 있다.           또한, 도 4에서 일례로 설명한 API 분석을 통해 “즐거움이 76%”, “슬픔이 42%”, “화남이 50%”, “두려움이 12%”, “놀람이 22%” 등의 상태를 추출한 경우에는, 높은 상태에 연관되는 이모티콘을 매칭할 수도 있다.           이후, 기존 방식과 달리, 이모티콘 생성부(3)의 단말 또는 서버(100)는 컨텐츠 입력부(2)의 단말 또는 서버(100)로 연관성 순으로 이모티콘을 배열하여 사용자에게 제공한다(S220).           이때, 컨텐츠 입력부(2)의 단말 또는 서버(100)의 사용자는 연관성 순으로 배치된 이모티콘 중에서 특정 이모티콘을 선택하고(S230), 선택된 이모티콘이 이모티콘 수신부(4)의 단말 또는 서버(100)로 전송된다(S150).           이때, 사용자는 배치된 이모티콘들 중에서 연관성이 높아 전단에 배치된 이모티콘을 선택할 가능성이 더 높을것이다.           한편, 이모티콘의 전송 전에 사용자로부터 추가적인 메시지가 입력되는 경우, 사용자의 컨텐츠 맥락이 변화되는이벤트가 발생될 수도 있다.           따라서 본 발명에서는 이러한 이벤트에 대응하여 이모티콘의 전송 전에 사용자로부터 추가적인 메시지가 입력되는 경우, 실시간으로 이를 반영하여 연관성 있는 이모티콘을 사용자가 선택하는 방법을 제공할 수도 있다.           도 7은 본 발명의 또 다른 일 실시예와 관련하여, 이모티콘의 전송 전에 사용자로부터 추가적인 메시지가 입력되는 경우, 실시간으로 이를 반영하여 연관성 있는 이모티콘을 사용자가 선택하는 방법을 설명하는 순서도이다.           도 7의 S110 단계 내지 S130 단계와 S210 단계는 도 6에서 설명한 S110 단계 내지 S130 단계와 S210 단계에 각각 대응되므로, 명세서의 간명화를 위해 설명은 생략한다.           도 7의 과정에서는 도 6에서의 과정과 달리, S210 단계 이후에, 컨텐츠 입력부(2)의 단말 또는 서버(100)가 텍스트, 보이스, 이미지, 동영상 중 어느 하나가 추가로 입력되는지 여부를 판단하는 단계(S310)를 더 포함한다.           이때, S310 단계에서 추가 입력된 컨텐츠가 없는 경우에는 도 6과 동일한 과정이 진행되지만, 추가 입력된 컨텐츠가 존재하는 경우에는, 이모티콘 생성부(3)의 단말 또는 서버(100)가 추가 입력된 컨텐츠를 기초로 형태소를분석하는 단계(S320) 및 동사, 명사, 형용사, 문장부호 등을 통해 추가 입력된 컨텐츠의 맥락을 분석하는 작업을 수행한다(S330).           또한,  이모티콘  생성부(3)의 단말 또는 서버(100)는 추가된 키워드를 고려하여 이모티콘을 매칭(S340)하고,S340 단계에서 매칭된 결과와 기존의 S210 단계를 통해 매칭된 결과를 실시간으로 반영하고, 연관성 순으로 이모티콘을 배열하여 컨텐츠 입력부(2)의 단말 또는 서버(100)로 전송하게 된다(S350).           이후, 컨텐츠 입력부(2)의 단말 또는 서버(100)의 사용자는 연관성 순으로 배치된 이모티콘 중에서 특정 이모티콘을 선택하고(S230), 선택된 이모티콘이 이모티콘 수신부(4)의 단말 또는 서버(100)로 전송된다(S150).           도 6 및 도 7에서 설명한 각각의 단계에 대해 도면을 들어 구체적으로 설명한다.           도 8은 도 6 또는 도 7에서 사용자가 입력한 컨텐츠를 통해 형태소를 분석하는 구체적인 일례를 도시한 것이다.           도 8은 도 6 또는 도 7의 S120 단계의 구체적인 일례를 도시한 것이다.           도 8을 참조하면, 컨텐츠 입력부(2)의 단말 또는 서버(100)의 사용자가 “가는 길에 버스를 잘못타서 오늘 늦을것 같은데 어떻게 하지?”라고 입력하는 일례가 도시된다.           이 경우, 이모티콘 생성부(3)의 단말 또는 서버(100)는 “가다”, “길”, “버스”, “잘 못”, “타다”, “오늘”, “늦다”, “어떻게”, “하다”, “?”의 형태소를 분석할 수 있다.           다음으로, 도 9는 도 8에서 분석된 형태소를 기초로 키워드를 추출하는 본 발명의 구체적인 일례를 도시한 것이다.           도 9는 도 6 또는 도 7의 S130 단계의 구체적인 일례를 도시한 것이다.           도 9를 참조하면, 이모티콘 생성부(3)의 단말 또는 서버(100)는 “가다”, “길”, “버스”, “잘 못”, “타다”, “오늘”, “늦다”, “어떻게”, “하다”, “?”의 감정, 상황, 문장 부호 등 형태소에서 의미 요소가강한 형태소를 골라낼 수 있다.     공개특허 10-2018-0080986           도 9에서는 “잘 못”, “늦다”, “어떻게”가 선택된 형태소가 될 수 있다.           또한, 도 10은 도 9에서 추출한 키워드를 기초로 데이터 베이스 내 연관성 있는 이모티콘을 매칭하는 구체적인작업의 일례를 도시한 것이다.           도 10은 도 6 또는 도 7의 S210 단계의 구체적인 일례를 도시한 것이다.           도 10을 참조하면, 도 9에서 선택된 형태소 “잘 못”, “늦다”, “어떻게”에 대응되는 복수의 이모티콘이 매칭되어 표시된다.           이후, 이러한 복수의 이모키톤은 연관성 순서에 따라 배치될 수 있다.           도 11은 도 10에서 매칭된 이모티콘을 연관성 순으로 사용자에게 배열하여 표시하는 구체적인 일례를 도시한 것이다.           도 11은 도 6의 S220 단계 또는 도 7의 S350 단계의 구체적인 일례를 도시한 것이다.           도 11을 참조하면, 0.0 내지 1.0의 점수를 나누어 연산된 수치에 의해 연관성이 높은 순서대로 해당 이모티콘컨텐츠의 이미지 주소 URL이 리스트화되어 추천되는 구체적인 모습을 도시하고 있다.           6개의 이모티콘은 각각 0.64, 0.63, 0.62, 0.71, 0.92, 0.59의 연관성 평가를 받을 수 있다.           도 12는 도 11에서 표시된 복수의 이모티콘 중 하나를 사용자가 선택하여, 선택한 이모티콘을 전송하는 구체적인 일례를 도시한 것이다.           도 12를 참조하면, 도 11에서 연산된 0.64, 0.63, 0.62, 0.71, 0.92, 0.59에서 높은 순서대로 이모티콘이 배치되어 컨텐츠 입력부(2)의 단말 또는 서버(100)에 표시되고, 사용자는 특정 이모티콘을 선택할 수 있으며, S150단계로서 선택된 이모티콘은 이모티콘이 이모티콘 수신부(4)의 단말 또는 서버(100)로 전송된다.           한편, 도 13은 도 7에서 설명한 S210 단계 이후에, 컨텐츠 입력부(2)의 단말 또는 서버(100)가 텍스트, 보이스,이미지, 동영상 중 어느 하나가 추가로 입력되는지 여부를 판단하는 단계(S310)를 더 포함되는 일례를 도시한것이다.           도 13에서는, 이모티콘을 전송하기 이전에, 컨텐츠 입력부(2)의 단말 또는 서버(100)를 통해 “맨날 내가 기다렸으니까 쌤통이다 ㅋㅋ”라는 추가 텍스트가 입력된다.           따라서 이모티콘 생성부(3)의 단말 또는 서버(100)가 추가 입력된 컨텐츠(“맨날 내가 기다렸으니까 쌤통이다ㅋㅋ”)를 기초로 형태소를 분석하는 단계(S320) 및 동사, 명사, 형용사, 문장부호 등을 통해 추가 입력된 컨텐츠의 맥락을 분석하는 작업을 수행 (S330)하고, 추가된 키워드를 고려하여 이모티콘을 매칭(S340)하며, S340 단계에서 매칭된 결과와 기존의 S210 단계를 통해 매칭된 결과를 실시간으로 반영하고, 연관성 순으로 이모티콘을배열하여 컨텐츠 입력부(2)의 단말 또는 서버(100)로 전송하게 된다(S350).           이후, 컨텐츠 입력부(2)의 단말 또는 서버(100)의 사용자는 도 13에 도시된 것과 같이, S340 단계에서 매칭된결과와 기존의 S210 단계를 통해 매칭된 결과를 실시간으로 반영하여 연관성 순으로 배치된 이모티콘 중에서 특정 이모티콘을 선택하고(S230), 선택된 이모티콘이 이모티콘 수신부(4)의 단말 또는 서버(100)로 전송할 수 있게 된다(S150).           한편, 전술한 본 발명의 구성에서는 “한글”을 기초로 적용되는 일례에 대해서 설명하였으나 본 발명의 내용이한글에 제한되는 것은 아니다.           도 14 및 도 15는 본 발명과 관련하여, 영어의 경우에 머신 러닝 기반의 인공지능 이모티콘 서비스를 제공하는구체적인 일례를 도시한 것이다.           도 14를 참조하면, 컨텐츠 입력부(2)의 단말 또는 서버(100)의 사용자가 “Yes, I’m on my-“ 의 텍스트(210)를 디스플레이부(151)를 통해 입력하는 경우, 도 3, 도 6 또는 도 7의 방법에 따라 복수의 관련된 이모티콘(220)이 디스플레이부(151) 상에 표시되는 구체적인 일례가 도시된다.           또한, 도 15를 참조하면, 컨텐츠 입력부(2)의 단말 또는 서버(100)의 사용자가 “it seems to be a littlelate…because I go- “ 의 텍스트(230)를 디스플레이부(151)를 통해 입력하는 경우, 도 3, 도 6 또는 도 7의방법에 따라 복수의 관련된 이모티콘(240)이 디스플레이부(151) 상에 표시되는 구체적인 일례가 도시된다.           한편, 전술한 본 발명에 따른 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 시스템(1)은 이모티콘 이미지가     공개특허 10-2018-0080986기기나 OS에 저장되지 않고, 클라우드에서 관리되어 사용 맥락에 맞춰 실시간으로 유동적으로 제공하는 시스템으로 활용될 수 있다.           또한, 전술한 본 발명에 따른 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 시스템(1)은 스마트폰(단말)에입력된 텍스트의 데이터 유형(감정, 상황, 정보)을 분류하여 별도의 조형 원칙에 따라 그래픽 이미지로 자동 변환되는 시스템으로 활용될 수 있다.           또한, 전술한 본 발명에 따른 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 시스템(1)은 인스턴트 메시지의텍스트에서 검출한 형태소와 의미 요소를 간접 광고 이미지로 치환하여, 이 기반의 광고 서비스를 제공하는 시스템으로 활용될 수 있다.           또한, 전술한 본 발명에 따른 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 시스템(1)은 채팅 시 전송한 음성 메시지에서 상황과 감정을 인식하여 이모티콘으로 대체하고, 이모티콘에 그 음성 메시지를 입혀서 함께 전송하는 시스템으로 활용될 수 있다.           전술한 본 발명의 구성이 적용되는 경우, 머신 러닝 기반의 인공지능 이모티콘 서비스 제공 시스템을 사용자에게 제공할 수 있다.           구체적으로 본 발명은 사용자의 메시지에 담긴 감정 요소와 맥락을 머신러닝 기반의 인공지능 기술로 분석하고캐릭터 이모티콘을 실시간으로 표현하는 시스템 및 어플리케이션을 사용자에게 제공할 수 있다.           또한, 본 발명은 메시지 분석을 통해 맥락 데이터(감정, 환경, 사물 등 요소)를 인식하고, 이를 시각적 의사소통 도구인 이모티콘으로 재가공하는 인공지능 기술 융합을 사용자에게 제공할 수 있다.           또한, 본 발명은 텍스트를 입력하는 사용 환경을 고려해서 특정 서비스나 어플리케이션에 국한하지 않고 범용으로 쓸 수 있는 어플리케이션 및 API를 사용자에게 제공할 수 있다.           또한, 본 발명은 사용자의 대화 습관 패턴을 학습하여 사용할수록 정확해지는 워드벡터 기반의 인공지능 머신러닝 시스템을 구축하고, 사용자에게 제공할 수 있다.           또한, 본 발명은 모바일 커뮤니케이션의 대부분을 차지하는 메시징 커뮤니케이션에 인공지능과 디자인 테크놀로지를 접목하여 더 정확하고 편리한 커뮤니케이션 경험을 제안하고, 번거로운 사용과 제한된 표현으로 텍스트 보조역할에 그치는 현재의 이모티콘 사용 경험을 혁신하여 인공지능이 대화를 분석하고 실시간으로 그래픽 요소를재조합하여 무한한 표현이 가능하도록 할 수 있다.           또한, 본 발명은 메시지 어플리케이션뿐만 아니라 입력 인터페이스를 사용하는 SNS, 블로그, 미디어 등에서 끊임없이 창작되는 콘텐츠에 디자인을 입히는 테크놀로지로 발전시킬 수 있다.           또한,  본 발명은 구매한 캐릭터 이모티콘 콘텐츠를 반복적으로 사용하는 기존의 사용 방식과 달리 키워드,감정, 사용빈도, 기호, 기후, 날짜, 시간, 장소, 이슈 등 다양한 변수를 분석하고 조합하여 매번 새로운 디자인사용이 가능하다.           또한, 본 발명은 입력하는 단어나 기호(개수) 요소에 따라 캐릭터 이모티콘 표현이 실시간으로 변화하여 사용자는 자신의 감정을 확인하고 표현할 수 있다.           또한, 본 발명은 사용자 친화적인 UX 디자인을 통해 연산과정에서 발생하는 딜레이와 같은 기술적인 제약을 줄이고 커뮤니케이션 과정을 좀 더 사용자에게 친숙하게 전달할 수 있다.           또한, 본 발명은 머신러닝을 통해 인공지능의 정확도를 지속적으로 높여갈 수 있다.           한편, 본 발명은 또한 컴퓨터로 읽을 수 있는 기록매체에 컴퓨터가 읽을 수 있는 코드로서 구현하는 것이 가능하다. 컴퓨터가 읽을 수 있는 기록매체는 컴퓨터 시스템에 의해 읽혀질 수 있는 데이터가 저장되는 모든 종류의기록장치를 포함한다. 컴퓨터가 읽을 수 있는 기록매체의 예로는 ROM, RAM, CD-ROM, 자기 테이프, 플로피 디스크, 광데이터 저장장치 등이 있으며, 또한 케리어 웨이브(예를 들어 인터넷을 통한 전송)의 형태로 구현되는 것도 포함한다.            또한, 컴퓨터가 읽을 수 있는 기록매체는 네트워크로 연결된 컴퓨터 시스템에 분산되어, 분산방식으로 컴퓨터가읽을 수 있는 코드가 저장되고 실행될 수 있다. 그리고, 본 발명을 구현하기 위한 기능적인(functional) 프로그램, 코드 및 코드 세그먼트들은 본 발명이 속하는 기술분야의 프로그래머들에 의해 용이하게 추론될 수 있다.            또한, 상기와 같이 설명된 장치 및 방법은 상기 설명된 실시례들의 구성과 방법이 한정되게 적용될 수 있는 것     공개특허 10-2018-0080986이 아니라, 상기 실시례들은 다양한 변형이 이루어질 수 있도록 각 실시례들의 전부 또는 일부가 선택적으로 조합되어 구성될 수도 있다.도면도면1     공개특허 10-2018-0080986도면2     공개특허 10-2018-0080986도면3     공개특허 10-2018-0080986도면4     공개특허 10-2018-0080986도면5     공개특허 10-2018-0080986도면6     공개특허 10-2018-0080986도면7도면8     공개특허 10-2018-0080986도면9도면10     공개특허 10-2018-0080986도면11     공개특허 10-2018-0080986도면12     공개특허 10-2018-0080986도면13     공개특허 10-2018-0080986도면14     공개특허 10-2018-0080986도면15   